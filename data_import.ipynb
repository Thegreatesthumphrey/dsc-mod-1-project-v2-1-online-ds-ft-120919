{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zippedData/tmdb.movies.csv',\n",
       " 'zippedData/imdb.title.crew.csv',\n",
       " 'zippedData/tn.movie_budgets.csv',\n",
       " 'zippedData/imdb.title.ratings.csv',\n",
       " 'zippedData/imdb.name.basics.csv',\n",
       " 'zippedData/imdb.title.principals.csv',\n",
       " 'zippedData/imdb.title.akas.csv',\n",
       " 'zippedData/bom.movie_gross.csv',\n",
       " 'zippedData/imdb.title.basics.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = glob(\"zippedData/*.csv\")\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files_dict = {}\n",
    "for filename in csv_files:\n",
    "    filename_cleaned = os.path.basename(filename).replace(\".csv\", \"\").replace(\".\", \"_\")\n",
    "    filename_df = pd.read_csv(filename, index_col = 0)\n",
    "    csv_files_dict[filename_cleaned] = filename_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\"movies_db.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_table_from_df(df, name, conn):\n",
    "    # Use try except\n",
    "    # it will try to make a table\n",
    "    # if a table exists the function will execute whatever you put in the except part\n",
    "    try:\n",
    "        df.to_sql(name, conn)\n",
    "        print(f\"Created table {name}\")\n",
    "    \n",
    "    # if the table exists t will tell you, and won't cause an error\n",
    "    except Exception as e:\n",
    "        print(f\"could not make table {name}\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not make table tmdb_movies\n",
      "Table 'tmdb_movies' already exists.\n",
      "could not make table imdb_title_crew\n",
      "Table 'imdb_title_crew' already exists.\n",
      "could not make table tn_movie_budgets\n",
      "Table 'tn_movie_budgets' already exists.\n",
      "could not make table imdb_title_ratings\n",
      "Table 'imdb_title_ratings' already exists.\n",
      "could not make table imdb_name_basics\n",
      "Table 'imdb_name_basics' already exists.\n",
      "could not make table imdb_title_principals\n",
      "Table 'imdb_title_principals' already exists.\n",
      "could not make table imdb_title_akas\n",
      "Table 'imdb_title_akas' already exists.\n",
      "could not make table bom_movie_gross\n",
      "Table 'bom_movie_gross' already exists.\n",
      "could not make table imdb_title_basics\n",
      "Table 'imdb_title_basics' already exists.\n"
     ]
    }
   ],
   "source": [
    "for name, table in csv_files_dict.items():\n",
    "    create_sql_table_from_df(table, name, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a .gitignore file that will ignore the files that you unzipped and the sqlite file\n",
    "# look at mine for a reference\n",
    "# you cannot push files bigger than 100 MB to github from your computer\n",
    "\n",
    "# you can create your file here in jupyter and open it from jupyter\n",
    "with open(\"./.gitignore\", \"w+\") as f:\n",
    "    f.write(\"*.sqlite\") # put files you want to ignore here\n",
    "    f.write(\"\\n\") # insert a new line after each file\n",
    "    f.write(\"zippedData/\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"zippedData/*.csv\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"zippedData/*.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zippedData/rt.reviews.tsv', 'zippedData/rt.movie_info.tsv']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_files = glob(\"zippedData/*.tsv\")\n",
    "tsv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_files_dict = {}\n",
    "for filename in tsv_files:\n",
    "    filename_cleaned = os.path.basename(filename).replace(\".tsv\", \"\").replace(\".\", \"_\")\n",
    "    filename_df = pd.read_csv(filename, index_col=0, delimiter='\\t', encoding = 'unicode_escape')\n",
    "    csv_files_dict[filename_cleaned] = filename_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_movie_info = pd.read_csv('zippedData/rt.movie_info.tsv', index_col=0, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_reviews = pd.read_csv('zippedData/rt.reviews.tsv', index_col=0, delimiter='\\t', encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54432, 7)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_movie_info.to_sql('rt_movie_info', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_reviews.to_sql('rt_reviews', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_title_basics = pd.read_csv('zippedData/imdb.title.basics.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_title_basics.to_sql('imdb_title_basics', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
